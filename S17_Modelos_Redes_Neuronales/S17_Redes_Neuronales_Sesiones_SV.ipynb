{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31faf529",
   "metadata": {},
   "source": [
    "# Sprint 17 - Redes Neuronales (Sesiones)\n",
    "\n",
    "**Versión para estudiantes**\n",
    "\n",
    "En este caso vamos a trabajar con **redes neuronales** que constituyen un tipo particular de modelos predictivos que se caracterizan y distinguen de otras tipologías porque no surgen de un algoritmo predefinido como tal, sino que su funcionamiento se motiva en intentar replicar los procesos del sistema neurológico humano. De ahí justamente su nombre y el hecho que su implementación requiera de la definción de una arquitectura específica para solucionar cada problema de pronóstico que se le presente.\n",
    "\n",
    "En este sentido, los modelos basados en redes neuronales, si bien tienen un sustento técnico lógico y coherente, suelen derivar en resultados extremadamente complejos que dificultan significativamente su interpretabilidad causal a partir de los atributos. Es por esta razón son llamados modelos \"de caja negra\", en los que incluso los científicos de datos que los desarrollan, desconocen los motivos o relaciones creados durante la etapa de entrenamiento.\n",
    "\n",
    "Lo anterior en todo caso no se debe considerar una limitación, puesto que su capacidad predictiva ha demostrado ser extremadamente alta incluso en la resolución de casos particularmente dificiles (i.e. clasificación de imágenes), y no hay que olvidar que este es siempre el propósito final del aprendizaje computacional. \n",
    "\n",
    "De forma adicional, en este caso vamos a aprender cómo se deben procesar datos representados en formas no tabulares. Concretamente vamos a preparar archivos de audio para extraer a partir de los sonidos atributos que sirvan como insumos de nuestros modelos predictivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83a3b0",
   "metadata": {},
   "source": [
    "## Entendimiento del contexto\n",
    "\n",
    "El dataset **RAVDESS** (*Ryerson Audio-Visual Database of Emotional Speech and Song*) fue creado en 2018 por Steven Livingstone y Frank Russo con el propósito de complementar investigaciones en ramas de la neurociencia, psicología y psiquiatría, así como el desarrollo de sistemas autónomos capaces de identificar emociones de seres humanos ya sea de manera visual o auditiva. Es así que RAVDESS cuenta con 7,356 archivos en los que actores vocalizan dos frases en idioma inglés y con un acento norteamericano neutro. En la totalidad de estos archivos hay versiones que son solamente audios, y otros que son videos sin sonido. Así también han versiones en las que los actores hablan y otras en las que cantan.\n",
    "\n",
    "Nuestro objetivo como científicos de datos en este caso consiste en crear un modelo predictivo capaz de identificar las emociones transmitidas en aquellos archivos de audio hablado, aportando de esta manera con las diferentes investigaciones realizadas en los distintos campos de la medicina neurológica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ffc56",
   "metadata": {},
   "source": [
    "## Entendimiento de los datos\n",
    "\n",
    "Carga las librerías que vamos a utilizar en nuestro proyecto. En primer lugar necesitaremos **pandas**, **numpy**, **matplotlib**, **re**, **warnings** y **glob**. Esta última nos ayudará a crear listas de los archivos que sean del mismo tipo y que estén contenidos en directorios específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c12b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "406fc7be",
   "metadata": {},
   "source": [
    "Para dar tratamiento a los audios, conviene que importes la librería **librosa**. Igualmente carga el módulo **IPython.display** para poder escuchar los audios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812dab86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3417728",
   "metadata": {},
   "source": [
    "De **Scikit-Learn** importa las funciones **MinMaxScaler**, **train_test_split**, **classification_report** y **accuracy_score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7f2739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "969a3156",
   "metadata": {},
   "source": [
    "Dado que nuestro modelo utilizará una red neuronal, importa **models**, **Input**, **layers**, **optimizers** y **utils** desde el módulo **tensorflow.keras**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19843e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4c5ab44",
   "metadata": {},
   "source": [
    "Ahora bien, puedes descargar los archivos de audio con los que vamos a trabajar desde \n",
    "\n",
    "https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio/data\n",
    "\n",
    "Este dataset contiene 1,440 archivos de audio (extensión .wav) los cuales contienen las ya mencionadas grabaciones realizadas por 24 actores de dos posibles frases:\n",
    "\n",
    "* *Kids are talking by the door*\n",
    "* *Dogs are sitting by the door*\n",
    "\n",
    "Adicional a esto, el nombre de cada archivo tiene una codificación dada por los criterios descritos a continuación:\n",
    "\n",
    "* Tipo de archivo \"03\" (03 = audio).\n",
    "* canal \"01\" (01 = hablado).\n",
    "* Emoción expresada (01 = neutro, 02 = calma, 03 = alegría, 04 = tristeza, 05 = enojo, 06 = miedo, 07 = desagrado, 08 = sorpresa).\n",
    "* Intensidad (01 = normal, 02 = alta).\n",
    "* Frase enunciada (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "* Repetición de la grabación (01 = 1ra repetición, 02 = 2da repetición).\n",
    "* Id del actor (01 to 24. Impares son hombres y pares son mujeres).\n",
    "\n",
    "Así por ejemplo, el archivo *03-01-06-02-02-02-11.wav* implica lo siguiente:\n",
    "\n",
    "* Tipo de archivo: audio\n",
    "* canal: hablado\n",
    "* Emoción expresada: miedo\n",
    "* Intensidad: alta\n",
    "* Frase enunciada: \"Dogs are sitting by the door\"\n",
    "* Repetición: 2da repetición\n",
    "* Id del actor: 11 (hombre)\n",
    "\n",
    "Explora por tanto estos archivos y establece un objetivo técnico, el método y métricas a utilizar, y el plan de acción para preparación e ingeniería de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57398300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50efac4c",
   "metadata": {},
   "source": [
    "**OBJETIVO TÉCNICO**\n",
    "\n",
    "< Aquí tu respuesta >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab321fe",
   "metadata": {},
   "source": [
    "**MÉTODO Y MÉTRICAS DE RENDIMIENTO**\n",
    "\n",
    "< Aquí tu respuesta >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1461dece",
   "metadata": {},
   "source": [
    "**PLAN DE ACCIÓN PARA PREPARACIÓN E INGENERÍA DE DATOS**\n",
    "\n",
    "< Aquí tu respuesta >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a2d1d8",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5f2fc",
   "metadata": {},
   "source": [
    "### Transformación de archivos de audio\n",
    "\n",
    "Para comprender el procedimiento a realizar, primero transformemos sólo el audio de ejemplo. Extrae la información de este archivo con las características de duración deseadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccebe90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8651a59",
   "metadata": {},
   "source": [
    "Visualiza cómo se comporta el sonido a través del tiempo. Vale que sepas que el sonido en este punto se representa como una medida de la señal eléctrica asociada a la presión o amplitud de aire generada, por lo que se expresa en microvoltios ($\\mu V$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20514a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46accf3f",
   "metadata": {},
   "source": [
    "Mejora la visualización de este comportamiento haciendo un acercamiento para conocer qué sucede con el sonido entre 1.5 y 1.51 segundos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a5aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f297df19",
   "metadata": {},
   "source": [
    "Un vector de señal de sonido como el anterior podría ya considerarse utilizable como una observación tabulable, sin embargo presenta dos inconvenientes relevantes:\n",
    "\n",
    "* En primer lugar, consta de aproximadamente 60,000 puntos o atributos lo cual podría ser riesgoso en cuanto a la confiabilidad de nuestro modelo al potencialmente incidir en la eficiencia computacional y en el surgimiento de sobreajuste. Por tanto hace falta un proceso de reducción dimensional.\n",
    "* En segundo lugar, una representación a nivel de microvoltios no es fácilmente interpretable desde la perspectiva humana para lo que constituye un sonido. Por consiguiente, hace falta llevar esta información a una unidad más significativa conceptualmente, siendo la mejor alternativa un decibel (dB) que representa una medida de volumen audible.\n",
    "\n",
    "Ante esto, se hace conveniente el empleo de un mecanismo específico para el tratamiento de audios llamado **Transformada de Fourier de tiempo corto (STFT por sus siglas en inglés)**. Esta transformación descompone la señal eléctrica del sonido en frecuencias sonoras representativas; y a partir de las frecuencias extraídas, es factible obtener los decibeles percibidos.\n",
    "\n",
    "Extrae por tanto las frecuencias sonoras del audio a través de la función `librosa.stft`. Vale indicar que el resultado obtenido será una suerte de tensor de donde nos interesa únicamente la parte \"real\" en valores absolutos (la física como ciencia usa estos trucos matemáticos aunque no lo creas).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df0b586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90593fae",
   "metadata": {},
   "source": [
    "Para tu conocimiento, la frecuencia es una medida de la tonalidad del sonido, por lo que si en el gráfico se observa una señal mayor en niveles de frecuencias más altos, esto representa que el audio en ese instante de tiempo sonará de forma más aguda. \n",
    "\n",
    "En todo caso, con la transformada de Fourier hemos reducido dimensionalmente nuestra observación de cerca de 60,000 atributos a solamente **130**. Aunque seguramente nos preocupa que hemos extraído en cada instante de tiempo **1,025** frecuencias, esto lo solucionaremos en los siguientes pasos.  \n",
    "\n",
    "Ahora bien, para facilitar la comprensión conceptual de nuestro sonido, convierte las frecuencias observadas a decibeles mediante la función `librosa.amplitude_to_db`. Incorpora el argumento `ref = 0` pues es el \"volumen\" de audio más bajo que se debería considerar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5bbf07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b8e84d5",
   "metadata": {},
   "source": [
    "Recordemos que el volumen audible por un humano suele ir entre 0 y 130 dB, por lo que en este instante de tiempo el audio es esuchado perfectamente por nuestros oídos.\n",
    "\n",
    "Visto esto, consolida todos los resultados alcanzados hasta ahora en un espectrograma del sonido que muestre las frecuencias y los decibeles alcanzados a través del tiempo. Usa para esto la funcion `librosa.display.specshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae84349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c060570",
   "metadata": {},
   "source": [
    "Finalmente, guarda una representación media de los decibeles del sonido para cada unidad de tiempo. Este resultado se constituye entonces en nuestra observación transformada del sonido con **130** atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820a8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "948deceb",
   "metadata": {},
   "source": [
    "Estamos listos para transformar y tabular todos nuestros archivos de audio. Crea una función que ejecute el procedimiento expuesto tal que al implementarla en un bucle se cuente con una tabla que contenga 1,440 filas y 130 atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b24fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1632b8e5",
   "metadata": {},
   "source": [
    "### Extracción de atributos adicionales y variable objetivo\n",
    "\n",
    "A partir del nombre de los archivos de audio, extrae todas las características y guárdalas en una tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012a492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6cc3d12",
   "metadata": {},
   "source": [
    "Excluye del dataframe aquellas variables poco relevantes para el análisis, es decir, las columnas que contienen el tipo, canal, frase y número de repetición de la grabación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd263e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3763473a",
   "metadata": {},
   "source": [
    "Ajusta las columnas restantes a fin de que:\n",
    "\n",
    "* La variable objetivo emoción sea numérica e inicie en 0.\n",
    "* La variable de intensidad tome valores 0 (intensidad normal) o 1 (intensidad alta).\n",
    "* Se tenga una columna en sustitución del id del actor la cual indique si dicha persona es hombre (1) o es mujer (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0a592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486cb727",
   "metadata": {},
   "source": [
    "Une finalmente esta información con el dataset de audios generado en la sección precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d4599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ae9a940",
   "metadata": {},
   "source": [
    "## Ingeniería de datos\n",
    "\n",
    "Ejecuta el plan de acción establecido para la ingeniería de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c2a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09f8266a",
   "metadata": {},
   "source": [
    "Antes de continuar, te sugiero guardar los subconjuntos de entrenamiento y prueba en archivos *csv*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ceb851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "950d8b48",
   "metadata": {},
   "source": [
    "## Modelo de red neuronal densa\n",
    "\n",
    "Una red neuronal consiste en una secuencia de capas interconectadas en las que se pueden definir múltiples entradas y salidas. Cada capa consta de uno o más nodos (llamados \"neuronas\" o \"unidades\") en los cuales las entradas se operan y generan como resultado una salida.\n",
    "\n",
    "Para comprender un poco mejor la idea expuesta, consideremos que una red neuronal básica es justamente la regresión lineal en la cual la matriz de atributos $X$ es la entrada. Esta se procesa en una única neurona que la multiplica por un vector de pesos $w_0$, generando como salida un nuevo vector $y_{p}$ al que llamamos predicción.\n",
    "\n",
    "$$ y_{p} = X\\cdot w_0 $$\n",
    "\n",
    "A partir de aquí los valores de $w_0$ se ajustan al minimizar una función de pérdida $L$ dada por $L = f(y-y_{p})$, donde $y$ corresponde a la salida esperada u observada. Esto es lo que se conoce como **retropropagación** y es el mecanismo fundamental de aprendizaje que tienen las redes neuronales. Como ya debes suponer la retropropagación requiere de la técnica de descenso de gradiente tal que\n",
    "\n",
    "$$ w_t = w_{t-1} - \\tau g_w $$\n",
    "\n",
    "donde $t$ es la iteración realizada, $\\tau$ es una tasa de aprendizaje (regularización), y $g_w$ es el gradiente de la función de pérdida correspondiente.\n",
    "\n",
    "![](NN_RegLin.png)\n",
    "\n",
    "Asumamos ahora que $y$ es una variable categórica que toma valores 0 o 1, la red neuronal básica que podemos utilizar no es otra que la regresión logística la cual es igual a la vista antes solo que en esta ocasión adicionamos una segunda capa. En esta nueva capa existe igualmente una sola neurona en la que $y_p$ se opera mediante una función **sigmoidal** para obtener $y_p^{(2)}$ tal que\n",
    "\n",
    "$$ y_p^{(2)} = \\frac{1}{1+\\exp{(-y_p)}} $$\n",
    "\n",
    "![](NN_RegLog.png)\n",
    "\n",
    "Notemos entonces que la regresión logística cuenta con las siguientes naturalezas distintas de capas en su arquitectura:\n",
    "\n",
    "* La primera contiene los atributos de entrada, por lo que en el contexto de redes neuronales tiene por nombre justamente *CAPA DE ENTRADA*. \n",
    "* La segunda que genera la salida $y_p$ a través de una combinación lineal adaptable a través de parámetros $w$, y que se conoce como *CAPA DENSA*.\n",
    "* La tercera que genera la salida $y_p^{(2)}$ a través de una transformación sigmoidal no adaptable, y que se denota como *CAPA DE ACTIVACIÓN*.\n",
    "\n",
    "Estos tipos son las que utilizaremos inicialmente para construir nuestro modelo predictor de emociones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f8b5f",
   "metadata": {},
   "source": [
    "### Red neuronal básica\n",
    "\n",
    "Esta red neuronal base que vamos a construir se denomina más comúnmente **Perceptrón** y tendrá las siguientes particularidades para corresponderse con el contexto de mejor forma:\n",
    "\n",
    "* Dado que se desean pronosticar 8 emociones distintas, su capa densa contendrá 8 neuronas. Cada una de ellas está encargada de encontrar aquellos patrones de una emoción en específico.\n",
    "* En vista que no se puede utilizar una función sigmoidal en la capa de activación pues esta solamente funciona para clasificaciones binarias, se aplicará la activación **softmax** dada por\n",
    "\n",
    "$$ y_{i,p}^{(2)} = \\frac{\\exp{(y_{i,p})}}{\\sum_j \\exp{(y_{j,p})}} $$\n",
    "\n",
    "donde $i$ y $j$ son índices que representan son cada una de las 8 emociones.\n",
    "\n",
    "Crea entonces la red neuronal con esta arquitectura (capas y retropropagación) y las funciones correspondientes de la librería **tensorflow**. Para la definición como tal de la red utiliza la función `models.Sequential`. Para la creación de las capas utiliza el método `add` y las funciones `Input`, `layers.Dense` y `layers.Activation` según corresponda. Para la definición del método de retropropagación considera el método `compile` con los siguientes argumentos:\n",
    "\n",
    "* `loss = \"sparse_categorical_crossentropy\"` que indica que se utilizará **entropía cruzada** como función de pérdida.\n",
    "* `optimizer = \"sgd\"` que indica que se aplicará descenso de gradiente como método de optimización.\n",
    "* `metrics = [\"acc\"]` que indica que se validará el rendimiento del modelo mediante la métrica de exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6ba4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed716ca7",
   "metadata": {},
   "source": [
    "El modelo definido consta de 1,064 parámetros propios de la capa densa, los mismos que surgen de tener 8 neuronas, cada una con 132 pesos (más un peso adicional representativo de la constante o intercepto de cualquier regresión). Entonces se cumple que\n",
    "\n",
    "$$ 8 \\times (132 + 1) =  1064 $$\n",
    "\n",
    "Lo anterior da cuenta de la complejidad que alcanzan los modelos basados en redes neuronales y que los transforma consecuentemente en \"cajas negras\".\n",
    "\n",
    "Ahora bien, para entrenar nuestro modelo base debemos considerar algunas particularidades de las redes neuronales:\n",
    "\n",
    "* En primer lugar, el aprendizaje de las mismas se da como en otros modelos con los datos de entrenamiento.\n",
    "* Sin embargo, las redes neuronales aprenden de forma dinámica y permanente visto que usan retropropagación. Por tanto, también es importante establecer cuantas *epocas* o iteraciones de entrenamiento se desean.\n",
    "* Tercero, cada una de estas épocas requiere de una validación por lo que igualmente se deben tomar en cuenta los datos de prueba.\n",
    "\n",
    "Visto esto, entrena el modelo mediante el método `fit` pero tomando en cuenta las particularidades expuestas y con al menos 250 épocas. Guarda los resultados en una variable llamada `train1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d395d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed791831",
   "metadata": {},
   "source": [
    "Visualiza la evolución de la exactitud a medida que las épocas fueron avanzando. Puedes extraer esta información del diccionario `train1.history` en la clave val_acc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9a313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10c65370",
   "metadata": {},
   "source": [
    "Genera ahora las predicciones con el modelo utilizando el método `predict`. Ten en cuenta que las predicciones de cada observación evidencian vectores de probabilidad para las 8 emociones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6bd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bb6091b",
   "metadata": {},
   "source": [
    "Crea una matriz de confusión y un reporte de clasificación con las predicciones alcanzadas por el modelo. Al finalizar guarda la métrica de exactitud alcanzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd261b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fe81845",
   "metadata": {},
   "source": [
    "### Red neuronal multicapa\n",
    "\n",
    "Un aspecto interesante en la creación de redes neuronales es que no existe limitación en cuanto a las capas de neuronas a incorporar dentro de su arquitectura, lo cual si bien incrementa la complejidad del modelo, abre la posibilidad a un mejoramiento del rendimiento.\n",
    "\n",
    "En este sentido, para la definición del siguiente modelo adiciona dos capas densas que busquen extraer los detalles más representativos de los datos de entrada, y con sus correspondientes capas de activación de tipo **ReLu**, que surgen de la función siguiente:\n",
    "\n",
    "$$ y_p^{(2)} = \\max{(0,y_p)} $$\n",
    "\n",
    "Estas nuevas capas colócalas a continuación de aquella de entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b92db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abb2f158",
   "metadata": {},
   "source": [
    "Entrena el modelo y visualiza la evolución de la exactitud dado el entrenamiento. Contrasta esta evolución con la exactitud del modelo base anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea7565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af69eab1",
   "metadata": {},
   "source": [
    "Evalúa el rendimiento del modelo y guarda la métrica de exactitud alcanzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd51895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d30fee45",
   "metadata": {},
   "source": [
    "### Red neuronal multicapa con otros hiperparámetros\n",
    "\n",
    "Al igual que en otros modelos, parte importante en el diseño de redes neuronales radica en la búsqueda de hiperparámetros que mejoren su rendimiento. En este sentido, en la siguiente red a crear ajusta lo siguiente a partir de la arquitectura anterior:\n",
    "\n",
    "* Cambia las dos primeras capas de activación de forma que utilicen funciones **tangente hiperbólica** y **sigmoidal**, respectivamente. Al respecto de la primera, la función que aquí se utiliza está dada por:\n",
    "\n",
    "$$ y_p^{(2)} = \\frac{e^{y_p} - e^{-y_p}}{e^{y_p} + e^{-y_p}} $$\n",
    "\n",
    "* Cambia el método numérico de optimización a uno conocido como **Adam (Optimizador de Momento Adaptativo)** que tiende a funcionar mejor cuando el número de atributos es alto. Para esto emplea la función `optimizers.Adam` con el argumento `learning_rate = 0.001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad0c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4057634d",
   "metadata": {},
   "source": [
    "Entrena el modelo y visualiza la evolución de su exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b1352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed91606b",
   "metadata": {},
   "source": [
    "Es importante que notes que tanto el uso de un optimizador tipo \"Adam\" como de neuronas de activación de tangentes hiperbólicas tienden a agilizar el aprendizaje al inicio de las épocas; sin embargo, a partir de cierto punto el ritmo de mejora del modelo es más lento, pudiendo requerir de un mayor número de iteraciones para estabilizarse.\n",
    "\n",
    "Evalúa el rendimiento del modelo y guarda la métrica de exactitud alcanzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642bd76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d27ca4af",
   "metadata": {},
   "source": [
    "## Modelo de red neuronal convolucional\n",
    "\n",
    "Las capas **convolucionales** son un tipo diferente en la arquitectura de redes neurales que procesan las entradas recibidas a modo de filtros que extraen características distintivas de los mismos. Para entender su funcionamiento, tomemos como ejemplo a una capa convolucional previamente utilizada y que se corresponde con la descomposición de una serie temporal. En este escenario, las entradas son justamente cada una de las observaciones $x_t$ a través del tiempo $[0,T]$. La capa en cuestión contaría con una sola neurona y 3 filtros, generando como salida lo siguiente considerando una ventana $K$ alrededor de cada tiempo $t$:\n",
    "\n",
    "1. Tendencia (media móvil): Dada por la expresión $ \\tau_{t} = \\sum_{i \\in K} w_{1,i}x_i $, donde los pesos $w_{1,i}$ son aquellos parámetros a optimizar por retropropagación al igual que en las redes densas vistas antes. \n",
    "\n",
    "2. Estacionalidad: Dada por la expresión $ \\sigma_{t} = \\sum_{i \\in K} w_{2,i}(x_i - \\tau_i) $, donde $w_{2,i}$ son los pesos a optimizar por retropopagación en este filtro.\n",
    "\n",
    "3. Residuo o factor aleatorio: Dado por la expresión $ \\rho_{t} = x_t - \\tau_t - \\sigma_t $ y que no tiene pesos.\n",
    "\n",
    "Es importante notar que en estas capas existen 3 hiperparámetros importantes:\n",
    "\n",
    "* La ventana $K$ conocida como *kernel*.\n",
    "* El salto o *stride* que especifica la cantidad de elementos que el *kernel* debe recorrer en el espacio temporal $[0,T]$ al momento de ejecutar los filtros. \n",
    "* El relleno o *padding* que define si la dimensión de la salida de la neurona será menor o igual a la de la entrada (Recuerda que al descomponer una serie podían generarse valores perdidos).  \n",
    "\n",
    "![](NN_Conv.png)\n",
    "\n",
    "Diseña entonces una red neuronal para la clasificación de emociones que utilice el siguiente orden de capas:\n",
    "\n",
    "* Una capa de entrada ajustada para ser utilizada por capas convolusionales.\n",
    "* Una capa convolucional de tipo `Conv1D` que funciona de forma equivalente a la descomposición de series evidenciada antes. Usa en este caso 5 filtros, un kernel de 10, un salto de 1 y un relleno de \"same\".\n",
    "* Una capa de activación tipo ReLu.\n",
    "* Una capa de tipo `Dropout` la cual convierte las salidas obtenidas en la capa precedente a 0 cuando las mismas tienen un valor menor a un umbral específico. Usa un valor de 0.1 para este umbral.  \n",
    "* Una de tipo `MaxPooling1D` que es de tipo convolusional y solamente consta de un filtro que extrae el máximo móvil. Usa en este caso un kernel de 10, un salto de 2 y un relleno de \"valid\" (menor dimensionalidad).\n",
    "* Nuevamente una capa `Dropout` con las mismas características a la anterior de este tipo.\n",
    "* Un capa de tipo `Flatten` que simplemente prepara el resultado obtenido para ser utilizado como entrada de una capa densa.\n",
    "* Una capa de tipo densa con 8 neuronas.\n",
    "* Una capa de activacion tipo softmax.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e719c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6779f44b",
   "metadata": {},
   "source": [
    "Notemos que las redes que utilizan capas convolucionales tienden a ser menos complejas puesto que la convolución como tal es una operación matemática de tipo agregadora. En nuestra arquitectura, ya no se consideran 132 atributos individuales sino que ahora existen 10 grupos dados por el *kernel* (más 1 correspondiente al intercepto) y 5 filtros. Por tanto, se deben otpimizar un total de $(10 + 1) \\times 5 = 55$ pesos.\n",
    "\n",
    "Entrena entonces esta red neuronal y visualiza la evolución de la métrica de exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2068de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "246a5e14",
   "metadata": {},
   "source": [
    "Evalúa el modelo creado y guarda la exactitud alcanzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918e14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fea0887",
   "metadata": {},
   "source": [
    "## Resultados alcanzados\n",
    "\n",
    "Para concluir con nuestro caso de estudio, visualicemos la capacidad predictiva de nuestra red neuronal mediante ejemplos concretos. Para esto en primer lugar escoge cualquier ejemplo del los datos de prueba, digamos el audio en la posición 20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08175bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d17fa0b",
   "metadata": {},
   "source": [
    "Extrae la emoción real y predicha de este ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe9d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a074a511",
   "metadata": {},
   "source": [
    "Finalmente grafica la probabilidad predicha de cada una de las emociones por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16e5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "251a9dff",
   "metadata": {},
   "source": [
    "Siéntete libre de probar con cualquier otro ejemplo proveniente de los datos.\n",
    "\n",
    "Si es de tu interés, puedes guardar el modelo ya entrenado mediante el siguiente código:\n",
    "\n",
    "```py\n",
    "mod_rn4.save(\"modelo_final.keras\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9be50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dc73b30",
   "metadata": {},
   "source": [
    "Y cargarlo mediante en otro notebook o programa de Python mediante este otro:\n",
    "\n",
    "```py\n",
    "modelo = models.load_model(\"modelo_final.keras\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0435b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b13f1db3",
   "metadata": {},
   "source": [
    "¡Todo listo! Has creado un modelo capaz de identificar las emociones de archivos de audio con una asertividad significativamente alta. Considera que otro modelo que prediga emociones al azar entre las 8 posibles de este caso, podría alcanzar únicamente valores de exactitud cercanos a 12%, así que estar cerca de un 60% es una mejora considerable. Sin embargo, el trabajo no concluye aquí intenta de probar distintas arquitecturas y configuraciones de redes neuronales con el propósito de intentar superar el rendimiento alcanzado hasta ahora."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
