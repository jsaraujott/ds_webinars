{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebad6c5c",
   "metadata": {},
   "source": [
    "# Sprint 14 - Descenso de Gradiente (Sesiones)\n",
    "**Versión para estudiantes**\n",
    "\n",
    "En este caso vamos a tratar el método de **descenso de gradiente** que aprovecha del poder computacional actual para generar modelos predictivos de alta asertividad. En este sentido, la aplicación de este procedimiento permite dos cosas importantes en el campo del aprendizaje computacional:\n",
    "\n",
    "* Por una parte, ayuda a potenciar algoritmos tradicionales (como los que que ya conoces) mediante un proceso de ensamblaje secuencial de los mismos. Este aspecto es el que trataremos a continuación.\n",
    "* Así también, facilita el desarrollo de nuevos algoritmos complejos para pronóstico como son las redes neuronales, y que veremos en otra ocasión.\n",
    "\n",
    "Además de lo anterior, en este caso vamos a enfocarnos en la técnica de reescalamiento, la cual hemos empleado hasta ahora como un medio para que los atributos numéricos mantengan un orden de magnitud similar entre ellos. Sin embargo, este método puede igualmente utilizarse con el propósito de garantizar un adecuado comportamiento en los valores que tome una variable objetivo. Y es que vale recordar que entre las principales condiciones necesarias para que ciertos algoritmos funcionen adecuadamente es que dicho objetivo siga una distribución aproximadamente normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1a8dc",
   "metadata": {},
   "source": [
    "## Entendimiento del contexto\n",
    "\n",
    "Has sido contratado como científico de datos en una empresa que ofrece seguros de salud. En vista de los bajos niveles de utilidad obtenidos en los últimos años, se te ha solicitado que les ayudes a pronosticar el costo anual incurrido por el servicio dado a cada cliente a fin de establecer de mejor manera las primas del próximo periodo fiscal en cuanto a renovaciones o nuevas pólizas.\n",
    "\n",
    "Los directores esperan que el modelo que desarrolles sea lo más asertivo posible, puesto que de los resultados que alcances dependerá el futuro financiero de la empresa. Adicionalmente, este proyecto se constituirá en la puerta de entrada para que la empresa inicie su proceso de transformación tecnológica, facilitando no solo el trabajo de los equipos comerciales al momento de cotizar, sino también permitiendo a la aseguradora mostrarse en el mercado como un competidor serio y con ambiciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6338b9e",
   "metadata": {},
   "source": [
    "## Entendimiento de los datos\n",
    "\n",
    "Importa las librerías con las que vas a trabajar incluyendo las siguientes funciones y grupos que ya conoces: `metrics`, `train_test_split` y `StandarScaler`. También importa la función `GradientBoostingRegressor` del grupo `ensemble` de **scikit - learn** que nos permite construir modelos con **potenciación de descenso de gradiente**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d06bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8004f7e6",
   "metadata": {},
   "source": [
    "Cuentas con el dataset **medical_cost**, que contiene información demográfica y conductual de 1,338 asegurados en la empresa respecto a lo siguiente:\n",
    "\n",
    "* age: Edad en años del asegurado.\n",
    "* sex: Sexo del asegurado (male, female).\n",
    "* bmi: Índice de masa corporal del asegurado (kg/m2).\n",
    "* children: Número de dependientes a cargo del asegurado (hijos, parejas, etc.).\n",
    "* smoker: Identificador si el asegurado es o no fumador.\n",
    "* region: Zona geográfica en la que reside el asegurado (northeast, southeast, northwest, southwest).\n",
    "* charges: Costo anual de servicios médicos asociados al asegurado en USD pagados por la empresa.\n",
    "\n",
    "Explora estos datos a fin de establecer el objetivo técnico, los algoritmos y métricas a utilizar, y el plan de acción para preparación e ingeniería de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bedd7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6419815e",
   "metadata": {},
   "source": [
    "**OBJETIVO TÉCNICO**\n",
    "\n",
    "< Aquí tu respuesta >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dceaee",
   "metadata": {},
   "source": [
    "**ALGORITMO Y MÉTRICAS DE RENDIMIENTO**\n",
    "\n",
    "< Aquí tu respuesta >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de0b48",
   "metadata": {},
   "source": [
    "**PLAN DE ACCION PARA PREPARACIÓN E INGENIERÍA DE DATOS**\n",
    "\n",
    "< Aquí tu respuesta >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb35d1",
   "metadata": {},
   "source": [
    "## Ingeniería de atributos\n",
    "\n",
    "Para empezar, separa los atributos de la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00dd767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd63f626",
   "metadata": {},
   "source": [
    "Ahora bien, es necesario reescalar la variable objetivo a fin de que la misma siga una distribución aproximadamente Normal. Existen diversas formas de hacer esto pero por ahora veamos la más directa y básica. Transforma la variable objetivo calculando su logaritmo con la función `np.log10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d266773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3fb050b",
   "metadata": {},
   "source": [
    "Vale indicar que el 1 que se adiciona garantiza que no existan indeterminaciones en el cálculo del logaritmo.\n",
    "\n",
    "Visto esto, vuelve a visualizar la distribución de esta variable transformada a fin de verificar si la misma ya cumple de mejor manera con el criterio de normalidad buscado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cfb35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ad28435",
   "metadata": {},
   "source": [
    "Existen otros métodos para \"normalizar\" variables y que te sugiero investigar:\n",
    "\n",
    "* Transformación Box-Cox\n",
    "* Transformación Yeo -Johnson\n",
    "\n",
    "Aquí algunos links que pueden ser de tu interés al respecto con su implementación ilustrativa en Python:\n",
    "\n",
    "* https://medium.com/@noorfatimaafzalbutt/understanding-the-box-cox-power-transformer-3dbb6613a593\n",
    "* https://medium.com/@paghadalsneh/box-cox-yeo-johnson-and-their-applications-950eec192886\n",
    "* https://medium.com/@lomashbhuva/mastering-data-transformations-a-deep-dive-into-box-cox-and-yeo-johnson-transformations-1beb17737196\n",
    "\n",
    "Visto esto, prosigamos con la ingeniería de nuestros datos. Codifica los atributos no numéricos mediante *One-Hot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8df512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0705deb0",
   "metadata": {},
   "source": [
    "Particiona el dataset en conjuntos de entrenamiento (75%) y prueba (25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37721d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca38d3e1",
   "metadata": {},
   "source": [
    "Escala finalmente los atributos numéricos con el método de estandarización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e33678f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7f02ab0",
   "metadata": {},
   "source": [
    "## Creación de modelo base con descenso de gradiente\n",
    "\n",
    "Al igual que en casos pasados, vamos a construir un algoritmo de regresión lineal, solo que en esta ocasión utilizaremos la técnica de **descenso de gradiente** que requiere de definir ciertos conceptos vinculados al área matemática del cálculo diferencial. Sea por tanto una función $L$ definida por\n",
    "\n",
    "$$ L:\\mathbb R^k \\rightarrow \\mathbb R $$\n",
    "\n",
    "donde $k$ corresponde al número de atributos que tenemos. Esta función se conoce como **función de pérdida** y nos sirve para optimizar el rendimiento de un modelo, pues al minimizarse se alcanza una mayor asertividad (o lo que es lo mismo, se generan menos \"pérdidas\").\n",
    "\n",
    "Tomemos entonces como función de pérdida al Error Cuadrático Medio (*MSE*) tal que\n",
    "\n",
    "$$ L(w) = \\frac{(Xw - y)^T\\cdot(Xw - y)}{n} $$\n",
    "\n",
    "donde $w$ es el vector de pesos de una regresión lineal, $X$ son los atributos, $y$ es el vector de objetivos, y $n$ es el número de registros. \n",
    "\n",
    "La **gradiente** de esta función respecto a $w$ ($g_w$), se define como el vector de derivadas parciales respecto a $w$ tal que\n",
    "\n",
    "$$ g_w = \\nabla_w L = \\frac{2\\cdot X^T\\cdot(Xw - y)}{n} $$\n",
    "\n",
    "Nos interesa entonces aproximar este gradiente al vector $[0 \\quad ... \\quad 0]^T$ mediante una selección adecuada de $w$, pues es allí donde se alcanzará potencialmente el mínimo de la función de pérdida.\n",
    "\n",
    "Ante esto, definamos el algoritmo de **descenso de gradiente** que nos permitirá cumplir con este propósito:\n",
    "\n",
    "1. Definir un vector inicial de pesos aleatorios $w_0$.\n",
    "2. Definir un número dado de iteraciones y una tasa de aprendizaje $\\tau$.\n",
    "3. Para cada iteración ejecutar lo siguiente:\n",
    "    * Calcular el gradiente $g_w$ de la función de pérdida.\n",
    "    * Actualizar los pesos tal que $w_i = w_{i-1} - \\tau g_w$ \n",
    "\n",
    "Notemos que dado este algoritmo se tienen las siguientes particularidades:\n",
    "\n",
    "* Los coeficientes del modelo cambiarán en magnitud proporcional a aquella del gradiente. Por lo que si $g$ tiende a cero, entonces prácticamente no se darán cambios a nivel de los pesos, lo cual implicará alcanzar un mínimo a nivel de la función de pérdida (y por consiguiente un rendimiento óptimo del modelo).\n",
    "* La tasa de aprendizaje $\\tau$ actúa como una suerte de regulador del \"descenso\", reescalando la magnitud de $g_w$ en cada iteración y evitando así que se alcancen mínimos locales indeseados.\n",
    "\n",
    "Visto esto aplica el algoritmo de **descenso de gradiente** con los datos de entrenamiento. Ten en cuenta lo siguiente:\n",
    "\n",
    "* Debes incorporar una columna adicional constante en $X$ que represente al intercepto de la regresión lineal.\n",
    "* Utiliza un temaño de paso pequeño para regular adecuadamente el descenso (i.e. 0.01). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c01385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09bd4945",
   "metadata": {},
   "source": [
    "Visualiza el comportamiento de todos los pesos alcanzados a través de las iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b67ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6949c93",
   "metadata": {},
   "source": [
    "Aquí es importante que sepas que hasta ahora con esta técnica no hemos mejorado lo que se consigue con el algoritmo de regresión lineal \"tradicional\". Simplemente hemos realizado una aproximación distinta para alcanzar los mismos resultados. Puedes verificar lo anterior, creando y entrenando un modelo con `LinearRegression` y extrayendo de aquí los pesos resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e576aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4234ce1c",
   "metadata": {},
   "source": [
    "Evalúa el rendimiento de este modelo con los datos del conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6af32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06b527ce",
   "metadata": {},
   "source": [
    "## Mejoramiento del modelo con GBM\n",
    "\n",
    "### Noción básica del GBM\n",
    "\n",
    "¿Cuánto falta para que nuestra predicción con el modelo base sea perfecta? Una forma de responder esto es mediante el cálculo del error $e$, que corresponde a $e = X\\cdot w - y$; o lo que es lo mismo $e = \\hat y - y$ donde $\\hat y = X\\cdot w$.\n",
    "\n",
    "A partir de aquí, notemos que la gradiente de la función de pérdida (MSE) respecto a $\\hat y$ esta dada por\n",
    "\n",
    "$$ g_{\\hat y} = \\nabla_{\\hat y} L = \\frac{2\\cdot (\\hat y - y)}{n} = \\frac{2\\cdot e}{n} $$\n",
    "\n",
    "Por lo que se puede concluir que $e \\propto g_{\\hat y}$. Esta proporcionalidad es relevante debido a que podemos utilizar nuevamente el algoritmo de descenso de gradiente para mejorar la calidad de nuestro pronóstico a partir de la predicción secuencial de esos gradientes.\n",
    "\n",
    "Entonces, haslo llevando a cabo los siguientes pasos:\n",
    "\n",
    "1. Definir una predicción base $\\hat y_0$ igual al promedio de la variable objetivo.\n",
    "2. Definir un número dado de iteraciones y un tamaño de paso $\\tau$.\n",
    "3. Para cada iteración ejecutar lo siguiente:\n",
    "    * Calcular el gradiente $g_{\\hat y}$ de la función de pérdida.\n",
    "    * Pronosticar con los atributos y un modelo básico estos gradientes, siendo el pronóstico $\\hat g_{\\hat y}$.\n",
    "    * Actualizar los $\\hat y$ tal que $\\hat y_i = \\hat y_{i-1} - \\tau \\hat g_{\\hat y}$ \n",
    "\n",
    "En cada iteración calcula además el coeficiente de determinación y trabaja con todos los datos pues esto es solamente un ejercicio ilustrativo para tener una noción del funcionamiento de GBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd49e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e2804c6",
   "metadata": {},
   "source": [
    "Visualiza como cambia el coeficiente de determinación gracias a la aplicación de la técnica de descenso de gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c2bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfec7b19",
   "metadata": {},
   "source": [
    "Nos damos cuenta que ahora sí estamos mejorando el R2 con el uso de este algoritmo frente a modelos \"tradicionales\". La lógica expuesta se conoce como **potenciación de descenso de gradiente** y a continuación vamos a formalizarla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e85688",
   "metadata": {},
   "source": [
    "### Definición formal de los GBM\n",
    "\n",
    "Los GBM son una familia de modelos predictivos que se construyen a partir del ensamblaje secuencial de modelos básicos aplicando el criterio de descenso de gradiente visto antes.\n",
    "\n",
    "En este sentido, sea $\\hat y_1$ la predicción del primero de estos modelos tal que\n",
    "\n",
    "$$ y = \\tau\\cdot \\hat y_1 + e_1 $$\n",
    "\n",
    "donde $e_1$ corresponde al error de predicción alcanzado y $\\tau$ es una tasa de aprendizaje que actúa como regulador del pronóstico. Sea ademas $g_1 = \\nabla_{\\hat y_1} L $ el gradiente de la función de pérdida $L$ respecto a $\\hat y_1$, por lo que se puede definir\n",
    "\n",
    "$$ \\hat y_2 = -\\underset{\\beta}{\\mathrm{argmax}} \\frac{(\\beta - g_1)^T(\\beta - g_1)}{n} $$\n",
    "\n",
    "De donde se obtiene que\n",
    "\n",
    "$$ y = \\tau\\cdot \\hat y_1 + \\tau\\cdot \\hat y_2 + e_2 $$\n",
    "\n",
    "Repitiendo este proceso $M$ veces se cumple que\n",
    "\n",
    "$$ y = \\tau\\cdot \\sum_{i=1}^{M} \\hat y_i + e_M $$\n",
    "\n",
    "donde para todo $i > 1$\n",
    "\n",
    "$$ \\hat y_i = -\\underset{\\beta}{\\mathrm{argmax}} \\frac{(\\beta - g_{i-1})^T(\\beta - g_{i-1})}{n} $$\n",
    "\n",
    "De esta definición se desprende que estos modelos constan de 2 hiperparámetros relevantes:\n",
    "\n",
    "* La tasa de aprendizaje $\\tau$.\n",
    "* El número de modelos $M$ que se ensamblan secuencialmente.\n",
    "\n",
    "Visto lo anterior, utiliza la función `GradientBoostingRegressor` para crear un modelo GBM de pronóstico. Aplica inicialmente los argumentos `n_estimators = 1000` y `learning_rate = 0.01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7923098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "979eb879",
   "metadata": {},
   "source": [
    "Evalua el rendimiento de este nuevo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bfaf75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "824b60e6",
   "metadata": {},
   "source": [
    "### Optimización de hiperparámetros GBM\n",
    "\n",
    "Encuentra el número de modelos base y la tasa de aprendizaje que generan un mejor rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3514f6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8d2a9ca",
   "metadata": {},
   "source": [
    "Crea y entrena un modelo final con los hiperparámetros óptimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67452a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6df29be0",
   "metadata": {},
   "source": [
    "Evalúa finalmente el rendimiento alcanzado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89eec85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f23401b0",
   "metadata": {},
   "source": [
    "Ya cuentas con un modelo altamente asertivo para pronosticar el costo de servicios de salud dadas las características demográficas y conductuales de clientes de la empresa. Solamente recuerda que las predicciones obtenidas se encuentran en uan escala logarítmica por lo que para des - escalar estos resultados deberás aplicar la fórmula:\n",
    "\n",
    "$$ Costo_{pred} = 10^{y_{pred}} - 1 $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
