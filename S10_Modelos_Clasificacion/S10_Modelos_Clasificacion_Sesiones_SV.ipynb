{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b48a3ec",
   "metadata": {},
   "source": [
    "# Sprint 10 - Modelos de Clasificación (Sesiones)\n",
    "\n",
    "En el caso a continuación buscamos profundizar en los conceptos y técnicas asociados a la creación de modelos de aprendizaje computacional supervisado para clasificación. En concreto vamos a presentar métodos que nos permitan: \n",
    "\n",
    "* Codificar variables no numéricas.\n",
    "* Escalar variables numéricas.\n",
    "* Balancear clases en variables objetivo.\n",
    "* Ajustar hiperparámetros.\n",
    "\n",
    "Además, para crear nuestro modelo utilizaremos un nuevo tipo de algoritmo de clasificación básico llamado **Regresión Logística**, del cual hablaremos en mayor detalle en las siguientes etapas del documento.\n",
    "\n",
    "Vale igualmente recordar los pasos que vamos a seguir y que te recomiendo tomar en cuenta para todos los modelos que desarrolles de aquí en adelante:\n",
    "\n",
    "* Entendimiento del contexto\n",
    "* Entendimiento de los datos\n",
    "* Preparación de datos\n",
    "* Ingeniería de datos\n",
    "* Creación de modelo base\n",
    "* Optimización del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf1fe1",
   "metadata": {},
   "source": [
    "## Entendimiento del contexto\n",
    "\n",
    "Una empresa de alquiler de vehículos de alta gama que mantiene sus servicios a escala mundial ha solicitado tu ayuda para predecir si un nueva persona que se contacta por sus servicios (*lead*) se convertirá en una venta o no. Lo anterior resulta importante ya que un pronóstico anticipado de la calidad de estos *leads*, permitirá una mejor asignación del esfuerzo comercial y de marketing.\n",
    "\n",
    "Para el área comercial el pronóstico anticipado le permitirá una asignación más asertiva del tiempo y los recursos necesarios para concretar ventas. Por ejemplo, si la predicción de un nuevo lead indica que se convertirá en venta (o lo que es lo mismo, que su probabilidad de conversión es alta), la gerencia comercial podría asignar su seguimiento a un ejecutivo no tan experimentado. Por el contrario, si la predicción indica que no será una venta (o que su probabilidad de conversión es baja), el ejecutivo a cargo podría tener un *seniority* mayor a fin de que a través de sus mejores conocimientos logre la conversión deseada.\n",
    "\n",
    "Para el área de marketing por su parte, esta información le permitirá en primera instancia evaluar si sus acciones pasadas han tenido resultados adecuados en lo que respecta a la atracción de clientes “rentables”. Así también le ayudará al desarrollo de mejores perfiles a futuro sobre los cuales focalizar su inversión en campañas, promociones e información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcbe2b3",
   "metadata": {},
   "source": [
    "## Entendimiento de los datos\n",
    "\n",
    "Antes de iniciar, carga las librerías y funciones que vas a utilizar. Ya conoces la función `train_test_split` y el grupo `metrics` de **Skicit-Learn**. Además de estas, carga las funciones listadas a continuación:\n",
    "\n",
    "* `StandardScaler` del grupo `preprocessing`.\n",
    "* `LogisticRegression` del grupo `linear_model`.\n",
    "* `permutacion_importance`del grupo `inspection`.\n",
    "\n",
    "Una librería adicional que vamos a utilizar en este caso es **imblearn** que contiene funciones y métodos para corregir problemas de balanceo en variables. Importa también de aquí la función `SMOTE` del grupo `over_sampling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde382a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17023a34",
   "metadata": {},
   "source": [
    "La empresa de alquiler ha compartido contigo un dataset llamado **leads**.\n",
    "\n",
    "Esta tabla contiene información histórica de poco más de 4,300 *leads* levantados por la empresa entre 2023 y 2024, que incluye las siguientes columnas:\n",
    "\n",
    "* id: Identificador único del lead que se contactó con la empresa.\n",
    "* producto: Nombre del producto de interés para el lead entre las opciones A, B y C.\n",
    "* sexo: Sexo del lead (F = Mujer, M = Hombre).\n",
    "* dominio_email: Dominio del correo electrónico del lead.\n",
    "* grupo_geografico: Región geográfica en la que reside el lead (Estados Unidos, Europa, Latinoamerica, Oceania y Otros).\n",
    "* fuente: Forma en que se contactó el lead con la empresa (Web = Página web, Remoto = Teléfono, Directo = Local físico, Red Social).\n",
    "* pautado: Si el lead se contactó con la empresa debido a una campaña de marketing.\n",
    "* fecha_creacion: Fecha en la que se dio el contacto entre el lead y la empresa.\n",
    "* fecha_conversion: De ser el caso, fecha en la que se convirtió el lead en una venta.\n",
    "* fecha_descalificacion: De ser el caso, fecha en que la empresa decidió terminal el contacto, y por ende se perdió la venta del lead.\n",
    "* estado: Si el lead se convirtió en venta (=1), o si se descalificó (=0).\n",
    "\n",
    "Explora el dataset y a partir de esto define lo siguiente:\n",
    "\n",
    "* Objetivo técnico del modelo.\n",
    "* Algoritmo y métricas de rendimiento a considerar.\n",
    "* Plan de acción para preparación e ingeniería los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2a0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ed3eb9b",
   "metadata": {},
   "source": [
    "**OBJETIVO TÉCNICO**\n",
    "\n",
    "< Aquí tu respuesta >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095494de",
   "metadata": {},
   "source": [
    "**ALGORITMO Y METRICAS DE RENDIMIENTO**\n",
    "\n",
    "< Aquí tu respuesta >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f9639",
   "metadata": {},
   "source": [
    "**PLAN DE ACCIÓN PARA PREPARACIÓN E INGENIERÍA DE DATOS**\n",
    "\n",
    "< Aquí tu respuesta >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6b5105",
   "metadata": {},
   "source": [
    "## Preparación de datos\n",
    "\n",
    "Lleva a cabo tu plan de acción a fin de preparar los datos para las siguientes etapas de análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2cb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "730dcf5f",
   "metadata": {},
   "source": [
    "## Ingeniería de datos\n",
    "\n",
    "Recordemos que la ingeniería de datos hace referencia a una serie de actividades que permiten “traducir” los datos a un lenguaje comprensible para el alogirtmo por implementar en el modelo de aprendizaje. En este sentido, habíamos tomado como simil a un niño aprendiendo a sumar, y ya sabíamos por tanto de la importancia de dividir nuestros datos en conjuntos de entrenamiento y prueba. Ahora adicionemos una premisa nueva a la ya mencionada:\n",
    "\n",
    "*Para que nuestro niño aprenda aún mejor, los ejercicios y el examen que le presentemos tienen que ser claros y comprensibles, se deben evitar por tanto todas aquellas cosas que resulten incomprensibles para una persona de su edad y condiciones.*\n",
    "\n",
    "En consecuencia, consideremos que los valores que toman variables no numéricas solamente hacen sentido cuando nosotros como humanos los interpretamos externamente. Tomemos como ejemplo el valor \"Europa\" de la columna grupo_geografico; para nosotros queda claro que esta palabra hace referencia al continente que es parte de hemisferio norte de nuestro planeta y donde existen muchos países con millones de habitantes. Sin embargo para un algoritmo esto no es así, pues para él la palabra \"Europa\" no representa más que una cadena de 6 caraceres (bytes) en un orden concreto. Es entonces necesario que llevemos estos valores a una representación más comprensible, y qué mejor que utilizar números los cuales sí tienen una interpretación propia y conocida por cualquier sistema computacional. \n",
    "\n",
    "Con este propósito, primero divide el dataset entre sus atributos y la variable objetivo (columna estado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320af23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad82a345",
   "metadata": {},
   "source": [
    "A continuación, codifica los atributos tipo texto de forma que se vuelvan numéricos. Te recomiendo usar la función `get_dummies` de **pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11694b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a3ce97d",
   "metadata": {},
   "source": [
    "El método de **codificación** que acabas de implementar se conoce como **One-Hot** y es muy utilizado en los procesos de ingeniería de atributos. La idea detrás del mismo es transformar cada valor de una variable no numérica en una columna de tipo buleano como se muestra en la siguiente imagen ejemplificativa:\n",
    "\n",
    "![](ohe.png)\n",
    "\n",
    "En nuestros atributos codificados del dataset solamente ten en cuenta lo siguiente:\n",
    "\n",
    "* Se ha cambiado los valores TRUE/FALSE por su equivalente numérico 1/0, respectivamente.\n",
    "* La dimensionalidad (cantidad de variables) del dataset se ha incrementado ya que por cada atributo original ahora existen 1 o más columnas nuevas correspondientes a cada uno de los valores posibles de dicho atributo.\n",
    "* Se excluye uno de los valores posibles de cada columna original puesto que no entrega ninguna información adicional y es por tanto redundante. Volviendo a nuestro ejemplo, nota que si \"Y\" y \"Z\" son ambos falsos, la única opción posible es que \"X\" sea verdadero.\n",
    "\n",
    "    ![](ohe2.png)\n",
    "\n",
    "Solamente queda ajustar los nuevos nombres de las columnas a formato *snake_case*. Haslo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c1d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba1815a0",
   "metadata": {},
   "source": [
    "Ahora bien, ya tenemos nuestros datos en un modo más comprensible para que el algoritmo a implementar los entienda. Puedes entonces proceder a particionar los datos en los subconjuntos de entrenamiento (75%) y prueba (25%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454cdb97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30f76432",
   "metadata": {},
   "source": [
    "Consideremos ahora la distribución de los atributos numéricos que mantenemos. Calcula el promedio y la desviación estandar para todas ellas en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e2fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a9accdd",
   "metadata": {},
   "source": [
    "Notemos que la variable tiempo_vida es particularmente diferente a las demás y esto puede resultar problemático. Para entender el porqué, volvamos a nuestro simil con la siguiente premisa:\n",
    "\n",
    "*Para que nuestro niño aprenda a sumar correctamente, es importante que entienda que la suma es un proceso transversal y homogeneo a cualquier número, es decir, no existen números más importantes que otros en la operación suma y el orden de los sumandos no altera el resultado. Por ejemplo $2 + 5 = 5 + 2$ o $100 + 81 = 81 + 100$ siempre, y ambos ejercicios siguen el mismo método aritmético.*\n",
    "\n",
    "Por consiguiente, es importante prevenir que el algoritmo \"crea\" que un atributo es más relevante que otros solo por mantener un distinto orden de magnitud. Entonces, para arreglar esto se aplica un proceso de ingeniería conocido como **escalamiento de variables**. Uno de los muchos métodos de escalamiento que existen es el de **Estandarización**, en el cual se transforma una variable $x$ a otra $x_{est}$ mediante la siguiente fórmula:\n",
    "\n",
    "$$ x_{est} = \\frac{x-\\bar x}{s_x} $$\n",
    "\n",
    "donde $\\bar x$ es el promedio de dicha variable y $s_x$ es su desviación estandar.\n",
    "\n",
    "El principal resultado de la estandarización es que el promedio de $x_{est}$ es ahora $0$ y su desviación estandar es $1$, y de ahí su nombre pues recuerda que estos parámetros son los que definen a la centralidad y la escala de una distribución Z (Normal Estandar).\n",
    "\n",
    "Estandariza entonces la variable tiempo_vida en el subconjunto de entrenamiento utilizando la función `StandardScaler` de **Scikit-Learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a42af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "986f960e",
   "metadata": {},
   "source": [
    "Transforma ahora este atributo en el subconjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee819be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8d88766",
   "metadata": {},
   "source": [
    "## Creación de modelo base\n",
    "\n",
    "Como ya mencionamos, en este caso concreto vamos a utilizar el algoritmo básico de **Regresión Logística**. Este algoritmo busca clasificar a los distintos registros que se le presenten mediante la estimación de la probabilidad que pertenezcan a una de las clases de la variable objetivo, dado los atributos que dicho registro posee, tal que:\n",
    "\n",
    "$$ \\mathbb{P}(y = 1 \\mid X) \\propto f(X) = \\sum_{x\\in X} w_x x = w_{x_1}x_1 + w_{x_2}x_2 + ... $$\n",
    "\n",
    "donde $w_x$ corresponde a los pesos específicos de cada atributo $x$, y se constituyen en parámetros ajustados durante el entrenamiento que no son controlados directamente por nosotros como científicos de datos. \n",
    "\n",
    "La expresión \"logística\" por su parte hace referencia a que esta probabilidad en cuestión surge de aplicar una función logística (también conocida como sigmoidal) de forma que:\n",
    "\n",
    "$$ \\mathbb{P}(y = 1 \\mid X) = \\frac{1}{1 + \\exp \\left( -\\sum_{x\\in X} w_x x \\right)} $$\n",
    "\n",
    "Entonces, si esta probabilidad alcanzada es mayor a un umbral (digamos 0.5) el algoritmo clasificará al registro en el grupo $y = 1$, caso contrario lo hará en $y = 0$. \n",
    "\n",
    "La principal ventaja de este algoritmo radica justamente en que utiliza un método probabilístico de clasificación y esto entrega de forma inmediata un grado de certeza respecto a si un caso pronosticado pertenece a uno u otro grupo en particular. Así también, si lo comparamos con los árboles de decisión, tiende a funcionar mejor cuando se utilizan atributos discretos (buleanos) y su grado de *complejidad computacional* es significativamente menor ante dimensionalidades mayores.\n",
    "\n",
    "En todo caso, entre sus principales desventajas radica el hecho que su visualización no es tan sencilla como lo eran los modelos basados en árboles de decisión. Y otra aún más relevante, en que su funcionamiento asume que las clases a pronosticar son *linealmente separables*, para lo cual se requeriría de una evaluación estadística exhaustiva sobre la interdependencia entre variables (no te preocupes si aún te cuesta comprender estos conceptos, los veremos y aplicaremos en próximos casos).\n",
    "\n",
    "Visto esto, crea un modelo base con la función `LogisticRegression` y entrénalo con los datos de entrenamiento. Utiliza de forma predeterminada los siguientes argumentos: \n",
    "\n",
    "* *solver = \"liblinear\"* que permite realizar una clasificación binaria como la que deseamos en datos que no son de gran volumetría. \n",
    "* *max_iter = 100* que evita que el mecanismo numérico por detrás de la función de **Scikit-Learn** dure un tiempo exchesivo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa36bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f56caa7",
   "metadata": {},
   "source": [
    "Estima la importancia de los distintos atributos aplicando la funcion `permutation_importance`. Para tu conocimiento, esta función calcula la importancia de cada variable a través de iteraciones en las que permuta aleatoriamente los distintos atributos establecidos y evalúa los cambios en el rendimiento del mismo; si los cambios observados son positivos, entonces el atributo tiene más importancia que uno con cambios negativos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f3890a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30f07e8f",
   "metadata": {},
   "source": [
    "Notemos que los atributos tiempo de vida, fuente_remoto y pautado son los más importantes en cuanto a la capacidad predictiva del algoritmo. Esto implica que parte de nuestras hipótesis establecidas en el objetivo técnico se cumplirían satisfactoriamente.\n",
    "\n",
    "Evalúa ahora el rendimiento del modelo base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e70bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "690947aa",
   "metadata": {},
   "source": [
    "El modelo base alcanza una exactitud de aproximadamente 80%, lo que implica que pronostica bien 8 de cada 10 nuevos leads que llegan a la empresa. Sin embargo, vale notar lo siguiente:\n",
    "\n",
    "* Le modelo tiene un mejor rendimiento en su capacidad predictiva de los leads que se descalifican respecto a aquellos que se convierten en venta. Esto podría resultar problemático desde el contexto del negocio dado que si se utilizan estos resultados, el equipo comercial gestionaría de forma equivocada sus recursos al asignar leads de alta calidad a ejecutivos con *seniority*, cuando esto no haría falta. Igualmente las inversiones en marketing podrían focalizarse erróneamente, alcanzando a grupos de clientes que no necesitan de estrategias de atracción como promociones.\n",
    "* Por otra parte, si consideramos que la gran mayoría de los leads de entrenamiento y prueba son de la clase descalificada, es lógico suponer que la capacidad predictiva aquí será mayor simplemente porque el algoritmo ha visto preferentemente estos casos. Lo anterios tenderá a sesgar la exactitud general del modelo llevándonos a la conocida \"paradoja de la exactitud\". Esta paradoja dice que cuando la variable objetivo no está balanceada respecto a sus clases, la exactitud no es una métrica confiable de la calidad del modelo.\n",
    "\n",
    "Por lo expuesto, guarda las métricas de exactitud y el F1 de la clase 1 (venta) alcanzadas por el modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0c653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61d6ade5",
   "metadata": {},
   "source": [
    "## Optimización del modelo\n",
    "\n",
    "Recuerda que en esta etapa buscamos maximizar el rendimiento del modelo mediante ajustes técnicos que incrementen los índices de asertividad. En este caso particularmente vamos a enfocarnos en dos procedimientos que nos ayuden a evitar la paradoja de la exactitud, a la vez que nos permitan aumentar los valores de las métricas consideradas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87acebb1",
   "metadata": {},
   "source": [
    "### Balanceo de clases\n",
    "\n",
    "Como su nombre puede ya darnos a entender, el balanceo hace referencia al uso de métodos estadísticos para equilibrar la frecuencia de posibles valores que tome una variable. A continuación te hago mención a los más populares:\n",
    "\n",
    "* Submuestreo: Consiste en eliminar aleatoriamente filas de la clase más frecuente hasta que haya balance. Conviene aplicarlo cuando el volumen de datos que se maneja es muy grande y el desbalanceo existente no es tan significativo.\n",
    "* Sobremuestreo: Consiste en simular aleatoriamente registros de la clase menos frecuente hasta que haya balance. Esta simulación puede aplicar diversas procedimientos como el *bootstrap* o el *SMOTE*.\n",
    "* Balanceo por pesos: Este método es específico de algoritmos generadores de parámetros de peso hacia sus atributos (como la regresión logística con el caso de $w_x$).\n",
    "\n",
    "Dado que el primero método mencionado es sumamente simple, vamos a obviarlo y a aplicar los otros en nuestro caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014783ae",
   "metadata": {},
   "source": [
    "**Balanceo por pesos**\n",
    "\n",
    "Este método ajusta los pesos $w_x$ resultantes de la función logística antes descrita mediante un factor inversamente proporcional a la frecuencia de cada clase. De esta manera, para la clase con menos registros en el dataset de entrenamiento se asigna una mayor relevancia que para la otra.\n",
    "\n",
    "Aplica entonces este método en un modelo nuevo y evalúa su rendimiento en cuanto a las métricas relevantes. PAra esto, incorpora el argumento `class_weight = \"balanced\"` en la definición del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75dc68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e310681",
   "metadata": {},
   "source": [
    "Por una parte, notemos que la exactitud sube marginalmente respecto al modelo base, pero dado que este nuevo modelo ha sido balanceado, podemos tener más confianza del valor alcanzado que ya no está sesgado. Adicionalmente, el balanceo permitió un mejor rendimiento predictivo para los casos de leads que se convierten en venta, lo cual es algo que deseábamos hacer en principio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a59709f",
   "metadata": {},
   "source": [
    "**Balanceo SMOTE**\n",
    "\n",
    "El método *SMOTE* (Synthetic Minority Oversampling Technique) funciona de la siguiente manera:\n",
    "\n",
    "1. Se escoge un dato cualquiera de la clase menos frecuente. \n",
    "2. Se determinan los datos que representan sus vecinos más cercanos (igual de la clase menos frecuente) y se escoge uno de ellos al azar.\n",
    "3. Se crea un nuevo dato \"sintético\" seleccionando un punto intermedio aleatorio que esté ubicado entre el dato originalmente seleccionado y su vecino escogido.\n",
    "4. Se repite este proceso un número de veces tal que la cantidad de datos creados compense lo más posible el desbalanceo original.\n",
    "\n",
    "Aplica este balanceo en los datos de entrenamiento con la función `SMOTE`, y verifica que se hayan balanceado las clases de la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa3246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f625bb5",
   "metadata": {},
   "source": [
    "Crea, entrena y evalúa un nuevo modelo con estos datos balanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b1202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22aff149",
   "metadata": {},
   "source": [
    "Los resultados alcanzados son similares a aquellos obtenidos por el método anterior. Esto no es más que una coincidencia y siempre vale la pena probar diferentes alternativas. Por tanto, te recomiendo que investigues sobre el método de balanceo con *bootstrap* para que amplíes tus herramientas técnicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896b465",
   "metadata": {},
   "source": [
    "### Ajuste de hiperparámetros\n",
    "\n",
    "Recuerda que los hiperparámetros consisten en todos aquellos argumentos que podemos controlar como científicos de datos previo a la ejecución de un algoritmo en un modelo de aprendizaje. Y en el caso de modelos de clasificación existe uno que no es tan evidente pero resulta múy util conocerlo y es el **umbral de clasificación**.\n",
    "\n",
    "Cuando explicabamos cómo funcionaba el algoritmo de regresión logística, mencionábamos que si la probabilidad obtenida por la función sigmoidal era mayor a un valor de 0.5, entonces la clase asignada para ese caso era 1 (venta). De hecho este criterio está definido de forma automática en nuestro modelo y podríamos cambiarlo estratégicamente para maximizar así la asertividad obtenida en los resultados. Pero, ¿Qué valor es finalmente el óptimo?\n",
    "\n",
    "Para responder a esta pregunta, primero obtén la probabilidad de conversión a venta predicha para cada lead de prueba por nuestro modelo balanceado por SMOTE. Utiliza el método `predict_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722bcb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93738701",
   "metadata": {},
   "source": [
    "Si revisamos el reporte de métricas y la matriz de confusion del modelo, con un umbral de 0.5 obtuvimos un grado de sensibilidad (recall) para la clase 1 de 88.3% debido a que de los 350 casos realmente convertidos en el subconjunto de prueba, 309 fueron correctamente pronosticados (Verdaderos Positivos). Llamemos por tanto a esta tasa por el nombre *TPR: True Positive Rate* tal que\n",
    "\n",
    "$$ TPR = Recall_{1} $$\n",
    "\n",
    "En línea con esto, se aprecia que existieron 172 Falsos Positivos, es decir, registros que realmente son descalificados pero el modelo predijo como ventas. Si dividimos estos falsos positivos en el total de casos verdaderamente descalificados, obtenemos una métrica conocida como *FPR: False Positive Rate* que en este caso alcanza un valor de 23.7%. Se cumple además que \n",
    "\n",
    "$$ FPR = 1 - Recall_{0} $$\n",
    "\n",
    "Estas métricas deberían cambiar en función del umbral que definamos. Prueba por ejemplo un umbral de 0.4 para calcular el *TPR* y el *FPR*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42bc8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40ea9e32",
   "metadata": {},
   "source": [
    "Con este nuevo umbral mejoramos en términos de sensibilidad de la clase 1 (mayor TPR), pero a su vez empeoramos en términos de su especificidad (mayor FPR). Existe por lo tanto un efecto conocido como *trade-off* entre esta métricas, por lo que nuestra meta debe ser encontrar un valor de umbral óptimo que maximice el *TPR* a la vez que minimice el *FPR*, generando por tanto un mejoramiento neto positivo. \n",
    "\n",
    "Dado que no es práctico buscar uno a uno todos los posibles umbrales existentes hasta encontrar aquel que es óptimo, puedes utilizar la función `metrics.roc_curve` para generar automáticamente las posibles alternativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e490b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f072bd55",
   "metadata": {},
   "source": [
    "Grafica ahora el *TPR* versus el *FPR* para todos los umbrales posibles. Incluye en el gráfico el punto donde se encuentran estas métricas para el umbral automático (0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a73146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "427d15f3",
   "metadata": {},
   "source": [
    "La curva obtenida se conoce como **Curva ROC (Receiver Operating Characteristic)** y tiene su origen en los estudios físicos de detección de señales, lo cual explica su nombre. Independiente de su origen, su utilidad en modelos de clasificación radica en que nos va a permitir encontrar el punto óptimo del umbral.\n",
    "\n",
    "Pensemos en lo siguiente: si seleccionamos un umbral que suba el *TPR* a 95% (+7pp), el *FPR* alcanzará un valor de aproximadamente 35% (+11pp); entonces el beneficio es menor al costo de esta estrategia y no conviene hacerla. Esta lógica simple nos da cuenta que de hecho deberíamos movernos en el otro sentido de la curva (reducir *TPR* y *FPR*). Pero para saber hasta dónde hacerlo, incluye en el gráfico anterior una recta con intercepto 1 y pendiente -1. \n",
    "\n",
    "Vale aclarar que la intersección entre esta recta y la curva ROC es el punto óptimo buscado, y para entender la razón de esto te sugiero que pienses el porqué de esta particularidad geométrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f057b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfa4cd2b",
   "metadata": {},
   "source": [
    "Encuentra entonces el valor del umbral en el que se da esta intersección y visualízalo en la gráfica anterior. En otras palabras, encuentra en qué punto se cumple que "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398140d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc1f67a9",
   "metadata": {},
   "source": [
    "### Modelo óptimo\n",
    "\n",
    "Ya tenemos todo lo necesario. Evalúa el rendimiento del modelo balanceado pero considerando el umbral óptimo encontrado.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db470945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17182b14",
   "metadata": {},
   "source": [
    "Guarda las métricas relevantes para el modelo óptimo y contrasta estos resultados con tu modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1f4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9201bc1",
   "metadata": {},
   "source": [
    "¡Listo! Has generado un modelo optimizado y confiable para pronosticar si un lead se convertirá en venta y que además tiene un valor de negocio importante al ser de utilidad para la toma de decisiones de los equipos comeciales y de marketing de la empresa de alquiler. Aún hay espacio de mejora, pero para ser una primera versión es un gran modelo. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
